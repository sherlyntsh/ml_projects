{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25c2005e",
   "metadata": {},
   "source": [
    "## 5. Conclusion & Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087a9471",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c069441",
   "metadata": {},
   "source": [
    "To build a binary classification model to assist the reddit moderators in classifying new posts between the statistics and machine learning subreddits, the PRAW (Python Reddit API Wrapper) package is utilized to access Reddit's API and facilitate the scraping of posts from the respective subreddits. A total of 999 posts have been scraped from r/statistics while 981 posts have been scraped from the r/machinelearning. Data cleaning steps such as handling missing values, tokenization, lemmatization and removal of stop words were then performed to reduce noise and improve the quality of the text data. The text data is then being converted into a matrix representation to facilitate the subsequent modeling steps.\n",
    "\n",
    "The Logistic Regression model was eventually selected as the final model to be used for the classification task. The model generated an accuracy of 0.96 and specificity of 0.96 on the test set. Based on the objective stated in the Project Overview, the selected model has achieved and exceeded the targets set out in the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f731bb",
   "metadata": {},
   "source": [
    "### Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb92514",
   "metadata": {},
   "source": [
    "Overall, the content of the posts provides a good foundation in building an accurate binary classification model. Aside from being able to assist in classifying new posts to ensure relevancy of the subreddits, the moderator is able to use the Logistic Regression model to identify words that relate to the respective subreddit topics and their relative importance. This is illustrated in the earlier review of features based on the modeling, where it was established that words such as 'llm', 'ai', 'ml', 'model', 'machine', 'training', 'chatgpt', 'neural' are identified as being contextually related to the machine learning topic while words such as 'statistic', 'statistical', 'variable', 'stats', 'test', 'sample', 'variance', 'interval' are contextually related to the statistics topic. This model would also be more cost-effective to deploy due to its lower computational complexity and efficiency in working with large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea8607c",
   "metadata": {},
   "source": [
    "### Future Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e166ba5",
   "metadata": {},
   "source": [
    "While the model is already fairly accurate, further refinements could be explored in the following aspects:\n",
    "1. Data cleaning: Perform a more thorough review and removal of stop words where necessary to further improve the quality of the text data.\n",
    "2. Building of additional models: Modeling using other more advanced models such as Support Vector Machines and Gradient Boosting in an attempt to further improve the outcome.\n",
    "3. Temporal analysis: Revise the scraping function to include the scraping of the posting date and time to analyse changes in keywords over time which may reveal trends and changes in the discussion on the subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57854150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
